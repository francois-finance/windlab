WindLab – Statistical Analysis & Probabilistic Modeling of Wind Turbine Wake Dynamics

WindLab is a full analysis environment developed for a wind-tunnel experiment (13/11/2025) designed to study the wake generated by an upstream wind turbine and its impact on a downstream turbine.

Beyond the physical experiment, the project focuses on:
	•	extracting meaningful information from noisy experimental time series,
	•	applying frequency-domain techniques to isolate structure from noise,
	•	performing probabilistic modeling of the wake behavior,
	•	running Monte Carlo simulations to quantify uncertainty,
	•	optimizing turbine placement under structural and stochastic constraints.

The methodology — FFT, denoising, spectral analysis, variance estimation, Monte Carlo, and scenario-based optimization — is directly transferable to any field where one must model a dynamic system with uncertainty from imperfect data.

⸻

Key Features

WindLab provides an end-to-end processing pipeline:
	•	load and clean LabVIEW measurement files (.lvm / .txt),
	•	visualize and compare upstream (P1) and downstream (P2) turbine signals,
	•	extract frequency content via FFT and apply adaptive filtering,
	•	compute spectrograms (STFT) to analyze time-frequency behavior,
	•	estimate statistical metrics such as variance and turbulence intensity,
	•	perform Monte Carlo simulations derived from the empirical distributions of the signals,
	•	compute optimal turbine spacing under uncertainty on a 2 km × 2 km domain,
	•	automatically generate a PDF report compiling figures and computed statistics.

⸻

Project Structure

windlab/
├── main.py                # Entry point – launches the GUI
├── gui.py                 # Tkinter interface + matplotlib integration

├── data/
│   ├── loader.py          # Robust parsing for LabVIEW .txt/.lvm formats
│   ├── preprocess.py      # FFT, filtering, statistical preprocessing

├── physics/
│   ├── wake_bastankhah.py # Gaussian wake model (Bastankhah 2014)
│   ├── wake_jensen.py     # Jensen / Park model

├── simulation/
│   ├── montecarlo.py      # Probabilistic scenario generation from data
│   ├── optimize.py        # Stochastic optimization of turbine positions

├── utils/
│   ├── plotting.py        # Visualizations: signals, FFT, spectrograms, layouts

├── reporting/
│   ├── pdf_generator.py   # Automated PDF reporting (ReportLab)

├── requirements.txt
├── .gitignore
└── README.md


⸻

Scientific and Statistical Perspective

WindLab treats wake measurements not only as physical data, but as realizations of stochastic processes, where the objective is to separate deterministic structure from turbulence-driven noise.

Several concepts mirror modern statistical and probabilistic modeling:

✔ Spectral Decomposition

Separates structured signal components from broadband noise — similar to separating latent factors from stochastic components.

✔ Local Variance & Turbulence Intensity

Analogous to estimating local volatility or diffusion parameters of a stochastic process.

✔ Monte Carlo Simulation

Used to propagate uncertainty from the measured wake signals into downstream energy recovery scenarios.

✔ Optimization Under Uncertainty

Turbine positioning is computed by maximizing expected performance while accounting for stochastic variability — a classic optimization-under-risk framework.

✔ Gaussian Wake Modeling

The Bastankhah wake equation is inherently probabilistic:
it models the wake deficit as a Gaussian distribution centered behind the turbine.

✔ Denoising & Time-Series Processing

Filtering, smoothing, FFT, and STFT are essential to reconstruct a usable signal — the same techniques used in any domain dealing with noisy measurements or high-frequency dynamics.

⸻

Goal of the Platform

WindLab provides an experimental yet statistically rigorous tool to:
	•	explore how uncertainty propagates through a dynamical system,
	•	test the sensitivity of a downstream turbine to wake variations,
	•	quantify the link between turbulence and energy recovery,
	•	evaluate optimal spatial configurations in a stochastic setting.

It demonstrates the full workflow from raw data → signal processing → statistical modeling → probabilistic simulation → optimization, which is central to many modern quantitative disciplines.
